{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Source adapted from:\n",
        "[News classification using HuggingFace DistilBert\n",
        "](https://www.kaggle.com/code/atechnohazard/news-classification-using-huggingface-distilbert/input)"
      ],
      "metadata": {
        "id": "i_hHL29MxESs"
      }
    },
    {
      "source": [
        "import kagglehub\n",
        "amananandrai_ag_news_classification_dataset_path = kagglehub.dataset_download('amananandrai/ag-news-classification-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "DxvEmJcd9TmR"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "k8k_rJhE9TmT"
      },
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "pmokmcaM9TmU"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertConfig, TFDistilBertModel\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Conv2D, Conv1D, MaxPooling1D, Dense, Dropout, GlobalMaxPooling1D, Input, Bidirectional, concatenate, Flatten, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# enable GPU memory growth if GPU is available\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    try:\n",
        "        for device in physical_devices:\n",
        "            tf.config.experimental.set_memory_growth(device, enable=True)\n",
        "        print('GPUs found and memory growth enabled.')\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# strategy for GPU or CPU\n",
        "if physical_devices:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print('Using MirroredStrategy for GPU(s).')\n",
        "else:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
        "    print('No GPU devices found, using OneDeviceStrategy for CPU.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rf5-a2S19TmV"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "6PGsTjGh9TmV"
      },
      "cell_type": "code",
      "source": [
        "TRAIN_FILE_PATH = '/kaggle/input/ag-news-classification-dataset/train.csv'\n",
        "TEST_FILE_PATH = '/kaggle/input/ag-news-classification-dataset/test.csv'\n",
        "\n",
        "data = pd.read_csv(TRAIN_FILE_PATH)\n",
        "testdata = pd.read_csv(TEST_FILE_PATH)\n",
        "\n",
        "# training data\n",
        "data = data.sample(n=1000)\n",
        "# test data\n",
        "testdata = testdata.sample(n=1000)\n",
        "\n",
        "X_train = data['Title'] + \" \" + data['Description']\n",
        "y_train = data['Class Index'].apply(lambda x: x-1).values # Classes need to begin from 0\n",
        "\n",
        "x_test = testdata['Title'] + \" \" + testdata['Description']\n",
        "y_test = testdata['Class Index'].apply(lambda x: x-1).values # Classes need to begin from 0\n",
        "\n",
        "maxlen = X_train.map(lambda x: len(x.split())).max()\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline"
      ],
      "metadata": {
        "id": "GUt6azujEtrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = {\n",
        "    0: [\"government\", \"country\", \"law\", \"poverty\", \"war\"],\n",
        "    1: [\"competition\",\"match\", \"player\", \"wins\", \"loses\"],\n",
        "    2: [\"business\", \"company\", \"stock\", \"market\", \"profit\"],\n",
        "    3: [\"science\", \"vaccine\", \"technology\", \"computer\", \"ai\"]\n",
        "}\n",
        "\n",
        "def baseline_predict(headline):\n",
        "  headline = str(headline).lower()\n",
        "\n",
        "  scores = {label: 0 for label in keywords}\n",
        "\n",
        "  for label, words in keywords.items():\n",
        "    for word in words:\n",
        "      if word in headline:\n",
        "        scores[label] += 1\n",
        "\n",
        "  best_label = max(scores, key=scores.get)\n",
        "\n",
        "  # If no keyword matches, the first category (world) would act as the default category.\n",
        "\n",
        "  if scores[best_label] == 0:\n",
        "    return 0\n",
        "\n",
        "  return best_label\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "y_pred_baseline = [baseline_predict(headline) for headline in x_test]\n",
        "\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "baseline_recall = recall_score(y_test, y_pred_baseline, average=\"macro\")\n",
        "baseline_precision = precision_score(y_test, y_pred_baseline, average=\"macro\")\n",
        "\n",
        "print(f\"Baseline accuracy: {baseline_accuracy:.2f}\")\n",
        "print(f\"Baseline recall: {baseline_recall:.2f}\")\n",
        "print(f\"Baseline precision: {baseline_precision:.2f}\")"
      ],
      "metadata": {
        "id": "qHb6O8XfEv4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6QGzTfLH9TmW"
      },
      "cell_type": "markdown",
      "source": [
        "# Define tokenizer"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "6mjvrENq9TmW"
      },
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "embed_size = 32\n",
        "distil_bert = 'distilbert-base-uncased'\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, padding='max_length', truncation=True, max_length=maxlen)\n",
        "\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in tqdm(sentences):\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=maxlen, padding='max_length', truncation=True,\n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])\n",
        "\n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCEG3gL49TmX"
      },
      "cell_type": "markdown",
      "source": [
        "# Tokenize data using defined tokenizer"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "E0etw05_9TmX"
      },
      "cell_type": "code",
      "source": [
        "# Tokenize desc and title train data\n",
        "X_train = tokenize(X_train, tokenizer)\n",
        "x_test = tokenize(x_test, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zB4cXAGn9TmY"
      },
      "cell_type": "markdown",
      "source": [
        "# Define model in TPU scope"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JURz0G5l9TmY"
      },
      "cell_type": "code",
      "source": [
        "class TransformerLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, transformer_model, **kwargs):\n",
        "        super(TransformerLayer, self).__init__(**kwargs)\n",
        "        self.transformer = transformer_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        # The transformer model returns a BaseModelOutput object\n",
        "        # The first element [0] or .last_hidden_state contains the sequence output\n",
        "        transformer_output = self.transformer(input_ids, attention_mask=attention_mask)\n",
        "        return transformer_output[0]\n",
        "\n",
        "with strategy.scope():\n",
        "    config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
        "    config.output_hidden_states = False\n",
        "    transformer_model = TFDistilBertModel.from_pretrained(distil_bert, config=config, from_pt=True)\n",
        "\n",
        "    # Instantiate the custom layer wrapper\n",
        "    transformer_wrapper = TransformerLayer(transformer_model)\n",
        "\n",
        "    input_ids_in = tf.keras.layers.Input(shape=(maxlen,), name='input_token', dtype='int32')\n",
        "    input_masks_in = tf.keras.layers.Input(shape=(maxlen,), name='masked_token', dtype='int32')\n",
        "\n",
        "    # Pass the KerasTensors to the custom wrapper layer\n",
        "    embedding_layer = transformer_wrapper([input_ids_in, input_masks_in])\n",
        "\n",
        "    X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(embedding_layer)\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "    X = tf.keras.layers.Dense(64, activation='relu')(X)\n",
        "    X = tf.keras.layers.Dropout(0.2)(X)\n",
        "    X = tf.keras.layers.Dense(4, activation='sigmoid')(X)\n",
        "    model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n",
        "\n",
        "    for layer in model.layers[:3]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.summary()\n",
        "    # Move model.compile inside the strategy.scope()\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89wzENV89TmY"
      },
      "cell_type": "markdown",
      "source": [
        "# Compile and fit model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sPEriXGA9TmY"
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "#     EarlyStopping(\n",
        "#         monitor='val_accuracy',\n",
        "#         min_delta=1e-4,\n",
        "#         patience=4,\n",
        "#         verbose=1\n",
        "#     ),\n",
        "    ModelCheckpoint(\n",
        "        filepath='weights.weights.h5',\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QCd2ZBIZ9TmY"
      },
      "cell_type": "code",
      "source": [
        "model.fit([X_train[0], X_train[1]], y_train, batch_size=32, validation_data=([x_test[0], x_test[1]], y_test), epochs=4, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ofVobW_E9TmZ"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights.weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zO9FJZuy9TmZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Test model with some arbitrary data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JPvQB0X39TmZ"
      },
      "cell_type": "code",
      "source": [
        "labels = ['World News', 'Sports News', 'Business News', 'Science-Technology News']\n",
        "\n",
        "test = ['New evidence of virus risks from wildlife trade', 'Coronavirus: Bank pumps £100bn into UK economy to aid recovery',\n",
        "        'Trump\\'s bid to end Obama-era immigration policy ruled unlawful', 'David Luiz’s future with Arsenal to be decided this week']\n",
        "test_seq = tokenize(test, tokenizer)\n",
        "test_preds = [labels[np.argmax(i)] for i in model.predict([test_seq[0], test_seq[1]])]\n",
        "\n",
        "for news, label in zip(test, test_preds):\n",
        "    print('{} - {}'.format(news, label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KABnN60X9TmZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Plot confusion matrix"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_LuLN1bT9TmZ"
      },
      "cell_type": "code",
      "source": [
        "preds = [np.argmax(i) for i in model.predict([x_test[0], x_test[1]])]\n",
        "cm  = confusion_matrix(y_test, preds)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm, figsize=(16,12), hide_ticks=True, cmap=plt.cm.Blues)\n",
        "plt.xticks(range(4), labels, fontsize=12)\n",
        "plt.yticks(range(4), labels, fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MAP-yZ5C9TmZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Get precision and recall scores"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MZm34zf49TmZ"
      },
      "cell_type": "code",
      "source": [
        "print(\"Recall of the model is {:.2f}\".format(recall_score(y_test, preds, average='micro')))\n",
        "print(\"Precision of the model is {:.2f}\".format(precision_score(y_test, preds, average='micro')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}